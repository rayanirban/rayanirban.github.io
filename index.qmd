---
title: ""
format:
  html:
    page-layout: full
    css: styles.css
---

::: {.top-nav}
::: {.top-nav-container}
<a href="#" class="nav-tab active" data-tab="about-me">About Me</a>
<a href="#" class="nav-tab" data-tab="education">Education</a>
<a href="#" class="nav-tab" data-tab="teaching">Teaching</a>
<a href="#" class="nav-tab" data-tab="work">Work</a>
<a href="#" class="nav-tab" data-tab="achievements">Achievements</a>
<a href="#" class="nav-tab" data-tab="skills">Skills</a>
<a href="#" class="nav-tab" data-tab="research">Research</a>
:::
:::

::: {.hero-section}
::: {.container}
::: {.main-content}

::: {.left-panel}
![](profile.jpg){.profile-img}

::: {.profile-info}
**Anirban Ray**
Ph.D. Student in Computational Image Restoration | Generative AI for Microscopy

:::

::: {.social-links}
[<img src="logos/github.png" class="social-icon-img" alt="GitHub">](https://github.com/rayanirban){.social-link target="_blank"} 
[<img src="logos/linkedin.png" class="social-icon-img" alt="LinkedIn">](https://www.linkedin.com/in/anirban-ray/){.social-link target="_blank"} 
[<img src="logos/scholar.png" class="social-icon-img" alt="Google Scholar">](https://scholar.google.de/citations?user=t-f_mwsAAAAJ&hl=en&authuser=1){.social-link target="_blank"} 
[<img src="logos/orcid.png" class="social-icon-img" alt="ORCID">](https://orcid.org/0000-0002-7285-6727){.social-link target="_blank"} 
[<img src="logos/humantechnopole.png" class="social-icon-img" alt="Human Technopole">](https://humantechnopole.it/en/people/anirban-ray/){.social-link target="_blank"}
[<img src="logos/twitter.png" class="social-icon-img" alt="Twitter">](https://x.com/anirbanray_){.social-link target="_blank"} 
[<img src="logos/bluesky.png" class="social-icon-img" alt="Bluesky">](https://bsky.app/profile/anirbanray.bsky.social){.social-link target="_blank"} 
[<img src="logos/instagram.png" class="social-icon-img" alt="Instagram">](https://instagram.com/anirbanray_){.social-link target="_blank"} 
:::

::: {.contact-links}
[<span class="contact-emoji">‚úâÔ∏è</span> Email](mailto:anirban.ray@fht.org){.social-link} [<span class="contact-emoji">üìÑ</span> CV](cv.pdf){.social-link target="_blank"}
:::

::: {.booking-link}
::: {style="text-align: center;"}
[<span class="contact-emoji">üìÖ</span> Book a meeting](https://calendar.app.google/ztwbew48GhVHQ63e7){.social-link target="_blank"} No agenda needed üòä
:::
:::

:::

::: {.right-panel}

<div class="tab-content active" data-tab-id="about-me">

## About Me

I am a final year Ph.D. Student in Computer Science at [Technische Universit√§t Dresden](https://tu-dresden.de){target="_blank" .flj} & [Human Technopole, Italy](https://humantechnopole.it){target="_blank" .flj}, advised by [Dr. Florian Jug](http://humantechnopole.it/en/people/florian-jug/){target="_blank" .flj}.
My research focuses on developing flow-matching models to restore biological imaging, advancing the intersection of artificial intelligence and the life sciences. I am passionate about AI4Science and deeply interested in how *[science philanthropy](https://sciencephilanthropyalliance.org/){target="_blank" .flj}* can accelerate discovery and innovation. </br>  
I hold a Masters degree in Computer Vision and Deep Learning from [Nagoya Institute of Technology](https://www.nitech.ac.jp/eng/){target="_blank" .flj}, Japan (2018), where I was advised by [Professor Jun Sato](https://researcher.nitech.ac.jp/html/56_en.html){target="_blank" .flj} and co-advised by [Associate Professor Fumihiko Sakaue](https://researcher.nitech.ac.jp/html/257_en.html){target="_blank" .flj}. Before beginning my doctoral journey, I worked as an Associate AI researcher at [Hitachi Research](https://www.hitachi.com/rd/){target="_blank" .flj} in Tokyo, applying deep learning to visual understanding and bioimage analysis.</br>  
I earned my Bachelors in Computer Science in Chennai, India, and was born and raised in [Kolkata, India](https://maps.app.goo.gl/uAYA9p9hDrgCzwhH7){target="_blank" .flj}, where I completed my Secondary and Higher Secondary education.

</div>

<div class="tab-content" data-tab-id="education">

## Education

::: {.education-item}
**Ph.D. in Computer Science | *2022 ‚Äì Present*** [Technische Universit√§t Dresden](https://tu-dresden.de){target="_blank" .flj} & [Human Technopole, Italy](https://humantechnopole.it){target="_blank" .flj} 
:::

::: {.education-item}
**Master of Engineering in Computer Science | *2016 ‚Äì 2018*** [Nagoya Institute of Technology](https://www.nitech.ac.jp/eng/){target="_blank" .flj}  
Advisor: [Prof. Jun Sato](https://researcher.nitech.ac.jp/html/56_en.html){target="_blank" .flj} and [Prof. Fumihiko Sakaue](https://researcher.nitech.ac.jp/html/257_en.html){target="_blank" .flj} | [Thesis](https://drive.google.com/file/d/1A7Gm2RS3L8SPyb9G9Ey5O350kh7DYZKk/view?usp=sharing){target="_blank"}
:::

::: {.education-item}
**Bachelor of Tech. in Computer Science and Engineering | *2011 ‚Äì 2015*** [Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology](https://www.veltech.edu.in/){target="_blank"}
:::

</div>

<div class="tab-content" data-tab-id="teaching">

## Teaching Experience

::: {.education-item}
**Teaching Assistant ‚Äì DL4MIA | [2022](https://humantechnopole.it/en/trainings/deep-learning-for-microscopy-image-analysis-2022/){target="_blank"}, [2023](https://dl4mia2023.humantechnopole.it/){target="_blank"}, [2024](https://meetings.embo.org/event/24-deep-learning-mia){target="_blank" .flj}  
**[Human Technopole, Milan, Italy](https://humantechnopole.it/){target="_blank" .flj}  

Supported the *Deep Learning for Microscopy Image Analysis* (DL4MIA) course across three consecutive editions. Responsibilities included mentoring participants, invited [lecture](https://x.com/anirbanray_/status/1789421846225404105){target="_blank"}, coding sessions, and guiding project work on AI-based microscopy restoration and segmentation. 
:::

::: {.education-item}
**Teaching Assistant ‚Äì DL@MBL | [2023](https://www.mbl.edu/education/advanced-research-training-courses/courses-calendar?trumbaEmbed=view%3Devent%26eventid%3D164013510){target="_blank"}, [2024](https://ai-mbl.github.io/2024/about/){target="_blank"}**[Marine Biological Laboratory, Woods Hole, USA](https://www.mbl.edu/){target="_blank" .flj} 

Contributed to hands-on sessions on deep learning for biological imaging. Provided mentoring and technical guidance to participants during lab exercises and research projects.
One of the project started there ended up being published in <a href="https://openreview.net/forum?id=HtlfNbyfOn" target="_blank">NeurIPS 2024</a>.
:::

</div>

<div class="tab-content" data-tab-id="work">

## Work Experience

::: {.education-item}
**Associate Researcher | *Apr 2018 ‚Äì Jan 2022*** [Hitachi Ltd., Tokyo, Japan](https://www.hitachi.com/rd/){target="_blank"}

Applied Deep Learning and Computer Vision for image analysis in the R&D Group's Center for Technology Innovation.
:::

::: {.education-item}
**Engineering Intern (AR Applications) | *Sep 2016*** [Sun Corporation, Konan, Japan](https://www.sun-denshi.co.jp/sc/product_service/acereal/){target="_blank"}

Developed augmented reality applications for AceReal smart glasses using Unity and Vuforia frameworks.
:::

::: {.education-item}
**Engineering Intern (Cloud Services) | *Aug 2014 ‚Äì Jan 2015*** [Machine Pulse (Mahindra Teqo), Mumbai, India](https://www.mahindrateqo.com/){target="_blank"}

Analyzed large-scale database migration strategies for renewable energy and logistics cloud systems.
:::

</div>

<div class="tab-content" data-tab-id="achievements">

## Special Achievements

::: {.education-item}
**Selected Participant ‚Äì Optical Microscopy & Imaging in the Biomedical Sciences (OMIBS) | *2023*** [Marine Biological Laboratory, USA](https://www.mbl.edu/education/advanced-research-training-courses/course-offerings/optical-microscopy-imaging-biomedical-sciences){target="_blank"}

Selected for this prestigious advanced microscopy course at the Marine Biological Laboratory, covering cutting-edge optical imaging techniques in biomedical sciences.
:::

::: {.education-item}
**Invited Contributor ‚Äì Alumni Voice Column | *2018*** [The University of Tokyo](https://www.u-tokyo.ac.jp/adm/utindia/en/whyjapan/fromalumni/executive_015.html){target="_blank"}

Invited by the Government of Japan and the University of Tokyo to share academic and professional experiences as part of Japan's international education initiative.
:::

::: {.education-item}
**Selected Participant ‚Äì International Computer Vision Summer School (ICVSS) | *2017*** [ICVSS, Italy](https://icvss.dmi.unict.it/icvss2017/){target="_blank"}

Chosen among 150 top global students (mostly PhDs) for advanced training and research presentation in computer vision.
:::

::: {.education-item}
**Aichi Monozukuri Scholarship | *2015*** [Aichi Prefectural Government, Japan](https://www.pref.aichi.jp/soshiki/kokusai/aichi-scholarship-program.html){target="_blank"}

Awarded full funding for Master's studies at Nagoya Institute of Technology. Selected among the top 10 students in Asia.
:::

::: {.education-item}
**Selected Participant ‚Äì Undergraduate Summer School on Computer Science | *2013*** [Indian Institute of Science, Bengaluru India](https://www.csa.iisc.ac.in/){target="_blank"}

Chosen among 60 top students from India for advanced topics and research presentation in computer science.
:::

</div>

<div class="tab-content" data-tab-id="skills">

## Skills

::: {.education-item}
**Computational Skills**

Python, PyTorch, OpenCV, NumPy, LaTeX, Git, SLURM, Bash, Linux
:::

::: {.education-item}
**Spoken Languages**

Bengali (Native), Hindi (Fluent), English (Fluent), Japanese (Conversational), Italian (Elementary)
:::

</div>

<div class="tab-content" data-tab-id="research">

## Research

### Current Research

::: {.project-item}

**<span style="font-size: 1.2em;">HazeMatching: Conditional Flow Matching for Microscopy Dehazing</span>**  
![](images/hazematching_teaser.png){fig-align="center" width="80%" alt="HazeMatching: Conditional Flow Matching for microscopy dehazing"}

A generative framework that restores optical microscopy images degraded by scattering and haze using Conditional Flow Matching (CFM). HazeMatching models the mapping between widefield and confocal modalities, enabling clearer visualization of biological structures.  
[GitHub](#){target="_blank" .flj} | [Paper (arXiv)](https://arxiv.org/abs/2506.22397){target="_blank" .flj} | [Demo](#){target="_blank"}
:::

### Past Research

::: {.project-item}
**Deep Learning for Industrial and Microscopy Image Analysis (2018‚Äì2021)**  

From 2018 to 2021, my research at Hitachi Ltd., Tokyo focused on developing deep learning‚Äìbased systems for high-precision image understanding in both industrial inspection and biomedical microscopy. I worked on combining computer vision and AI-driven automation for identifying and quantifying objects of interest in complex visual data.

In 2021, I co-authored the paper [*Quantitative Analysis System for Bacterial Cells in SEM Images Using Deep Learning*](https://ieeexplore.ieee.org/abstract/document/9400322){target="_blank" .flj} (*CISS 2021*), introducing a neural architecture for accurate segmentation and counting of bacterial cells from scanning electron microscopy (SEM) data. This was followed by [*Deep Learning Based Bacteria Classification from SEM Images Using a Combination of Membrane and Internal Features*](https://ieeexplore.ieee.org/abstract/document/9751170){target="_blank" .flj} (*CISS 2022*), where we improved bacterial classification by jointly modeling morphological and internal structural cues.

Building on this foundation, I co-invented several patented AI image-processing systems that enable adaptive feature extraction and object detection for microscopy and industrial imaging. These include [US Patent 12,327,363](https://patents.google.com/patent/US12327363B2){target="_blank"}, [US Patent 12,211,213](https://patents.google.com/patent/US12211213B2){target="_blank"}, and [EP Patent 3961562A1](https://patents.google.com/patent/EP3961562A1){target="_blank"}, describing methods and apparatuses for generating neural models that identify and segment objects of interest from images.

This phase of my work established a foundation in AI-driven visual understanding, bridging industrial automation with quantitative biological imaging, and set the stage for my later research in generative and flow-based models for microscopy restoration.

![Figure: Conceptual schematic of deep learning pipelines developed at Hitachi for automated bacterial analysis and industrial image understanding.](images/past_research_teaser.png){width="100%" style="border-radius: 1rem; box-shadow: 0 0 10px rgba(0,0,0,0.1);"}
:::

</div>

:::

::: {.right-side-column}
::: {.news-block}
### News

::: {.news-items-container}
{{< include news.md >}}
:::
:::
:::
:::
:::
:::



::: {style="text-align: center; color: var(--text-secondary); font-size: 0.85rem; margin-top: 0.5rem; padding-bottom: 1rem;"}
If you use this template, please acknowledge the original design by linking here üòä
:::

```{=html}
<script>
document.addEventListener('DOMContentLoaded', function() {
  const navTabs = document.querySelectorAll('.nav-tab');
  const tabContents = document.querySelectorAll('.tab-content');
  
  navTabs.forEach(tab => {
    tab.addEventListener('click', function(e) {
      e.preventDefault();
      
      // Remove active class from all tabs and contents
      navTabs.forEach(t => t.classList.remove('active'));
      tabContents.forEach(content => content.classList.remove('active'));
      
      // Add active class to clicked tab
      this.classList.add('active');
      
      // Show corresponding content
      const tabId = this.getAttribute('data-tab');
      const contentToShow = document.querySelector(`[data-tab-id="${tabId}"]`);
      if (contentToShow) {
        contentToShow.classList.add('active');
      }
    });
  });
});
</script>
```


<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Anirban Ray</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
.display.math{display: block; text-align: center; margin: 0.5rem auto;}
</style>


<link href="./profile.jpg" rel="icon" type="image/jpeg">
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-html-734cb40618f438257b19a1e532635a32.min.css" rel="stylesheet" append-hash="true" data-mode="light">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="Anirban Ray">
<meta property="og:description" content="PhD Student in Computer Science at Technische Universit√§t Dresden &amp; Human Technopole, Italy. Research focuses on flow-matching models for biological image restoration.">
<meta property="og:site_name" content="Anirban Ray">
<meta name="twitter:title" content="‚Äì Anirban Ray">
<meta name="twitter:creator" content="@anirbanray_">
<meta name="twitter:site" content="@anirbanray_">
<meta name="twitter:card" content="summary">
</head>

<body>





<div class="top-nav">
<div class="top-nav-container">
<p><a href="#" class="nav-tab active" data-tab="about-me">About Me</a> <a href="#" class="nav-tab" data-tab="research">Research</a> <a href="#" class="nav-tab" data-tab="education">Education</a> <a href="#" class="nav-tab" data-tab="teaching">Teaching</a> <a href="#" class="nav-tab" data-tab="work">Work</a> <a href="#" class="nav-tab" data-tab="achievements">Achievements</a> <a href="#" class="nav-tab" data-tab="skills">Skills</a> <a href="#" class="nav-tab" data-tab="talks">Talks</a> <a href="#" class="nav-tab" data-tab="showcase">Showcase</a></p>
</div>
</div>
<div class="hero-section">
<div class="container">
<div class="main-content">
<div class="left-panel">
<p><img src="profile.jpg" class="profile-img img-fluid"></p>
<div class="profile-info">
<p><strong>Anirban Ray</strong> PhD Student in Computational Image Restoration | Generative AI for Microscopy</p>
</div>
<div class="social-links">
<p><a href="https://github.com/rayanirban" class="social-link" target="_blank"><img src="logos/github.png" class="social-icon-img" alt="GitHub"></a> <a href="https://www.linkedin.com/in/anirban-ray/" class="social-link" target="_blank"><img src="logos/linkedin.png" class="social-icon-img" alt="LinkedIn"></a> <a href="https://scholar.google.de/citations?user=t-f_mwsAAAAJ&amp;hl=en&amp;authuser=1" class="social-link" target="_blank"><img src="logos/scholar.png" class="social-icon-img" alt="Google Scholar"></a> <a href="https://orcid.org/0000-0002-7285-6727" class="social-link" target="_blank"><img src="logos/orcid.png" class="social-icon-img" alt="ORCID"></a> <a href="https://humantechnopole.it/en/people/anirban-ray/" class="social-link" target="_blank"><img src="logos/humantechnopole.png" class="social-icon-img" alt="Human Technopole"></a> <a href="https://x.com/anirbanray_" class="social-link" target="_blank"><img src="logos/twitter.png" class="social-icon-img" alt="Twitter"></a> <a href="https://bsky.app/profile/anirbanray.bsky.social" class="social-link" target="_blank"><img src="logos/bluesky.png" class="social-icon-img" alt="Bluesky"></a> <a href="https://instagram.com/anirbanray_" class="social-link" target="_blank"><img src="logos/instagram.png" class="social-icon-img" alt="Instagram"></a></p>
</div>
<div class="contact-links">
<p><a href="mailto:anirban.ray@fht.org" class="social-link"><span class="contact-emoji">‚úâÔ∏è</span> Email</a> <a href="files/CV.pdf" class="social-link" target="_blank"><span class="contact-emoji">üìÑ</span> CV</a></p>
</div>
<div class="booking-link">
<div style="text-align: center;">
<!-- [<span class="contact-emoji">üìÖ</span> Book a meeting](https://calendar.app.google/ztwbew48GhVHQ63e7){.social-link target="_blank"} No agenda needed üòä -->
</div>
</div>
</div>
<div class="right-panel">
<section id="about-me" class="tab-content active" data-tab-id="about-me">
<h2 class="anchored">About Me</h2>
<p>I am a final year PhD Student in Computer Science at <a href="https://tu-dresden.de" class="flj" target="_blank">Technische Universit√§t Dresden</a> &amp; <a href="https://humantechnopole.it" class="flj" target="_blank">Human Technopole, Italy</a>, advised by <a href="http://humantechnopole.it/en/people/florian-jug/" class="flj" target="_blank">Dr.&nbsp;Florian Jug</a><span class="tooltip-trigger" data-tooltip="Wondering why this arrangement?: I was selected through the IMPRS-CellDevoSys PhD Program at the Max Planck Institute of Molecular Cell Biology and Genetics (MPI-CBG) to work with Dr. Florian Jug. At the time of my selection, he was a Principal Investigator at MPI-CBG and my PhD program was affiliated with the Faculty of Computer Science at Technische Universit√§t Dresden. However, he relocated to Human Technopole in Milan, Italy before I officially commenced my PhD. In this new arrangement, while I could no longer keep my affiliation with MPI-CBG, I could keep my affiliation with Technische Universit√§t Dresden.">‚àÄ</span>. My research focuses on developing flow-matching models to restore degraded biological images and applying other deep learning methods to inverse problems in microscopy for biological data, advancing the intersection of artificial intelligence and the life sciences. I am passionate about AI4Science and deeply interested in how <em><a href="https://sciencephilanthropyalliance.org/" class="flj" target="_blank">science philanthropy</a></em> can accelerate discovery and innovation. <br><br>
I hold a Masters degree in Computer Vision and Deep Learning from <a href="https://www.nitech.ac.jp/eng/" class="flj" target="_blank">Nagoya Institute of Technology</a>, Japan (2018), where I was advised by <a href="https://researcher.nitech.ac.jp/html/56_en.html" class="flj" target="_blank">Professor Jun Sato</a> and co-advised by <a href="https://researcher.nitech.ac.jp/html/257_en.html" class="flj" target="_blank">Associate Professor Fumihiko Sakaue</a>. Before beginning my doctoral journey, I worked as an Associate AI researcher at <a href="https://www.hitachi.com/rd/" class="flj" target="_blank">Hitachi Research</a> in Tokyo, applying deep learning to visual understanding and bioimage analysis.<br><br>
I earned my Bachelors in Computer Science in Chennai, India, and was born and raised in <a href="https://maps.app.goo.gl/uAYA9p9hDrgCzwhH7" class="flj" target="_blank">Kolkata, India</a>, where I completed my Secondary and Higher Secondary school education. Outside of research, I enjoy staying active through badminton, ping pong, and hiking, and I also keep a light strength-training routine as well.</p>
</section>
<section id="showcase" class="tab-content" data-tab-id="showcase">
<h2 class="anchored">Showcase</h2>
<p class="subtitle" style="margin-bottom: 2rem; color: #a1a0a0ff; font-size: 1.0rem;">
Some highlights of my journey üòá
</p>
<div class="showcase-grid">
<div class="showcase-item linkedin-embed">
<p><iframe src="https://www.linkedin.com/embed/feed/update/urn:li:activity:7417062191268462592" height="600" width="100%" frameborder="0" allowfullscreen="" title="Embedded post"></iframe></p>
</div>
<!-- Twitter/X Embeds - First 8 (2 rows) load immediately -->
<div class="showcase-item twitter-embed" data-priority="immediate">
<blockquote class="twitter-tweet" data-theme="dark">
<p lang="en" dir="ltr">
Loading tweet‚Ä¶
</p>
<a href="https://twitter.com/anirbanray_/status/1691389839369732096">View Tweet</a>
</blockquote>
</div>
<div class="showcase-item twitter-embed" data-priority="immediate">
<blockquote class="twitter-tweet" data-theme="dark">
<p lang="en" dir="ltr">
Loading tweet‚Ä¶
</p>
<a href="https://twitter.com/anirbanray_/status/1691589088149664052">View Tweet</a>
</blockquote>
</div>
<div class="showcase-item twitter-embed" data-priority="immediate">
<blockquote class="twitter-tweet" data-theme="dark">
<p lang="en" dir="ltr">
Loading tweet‚Ä¶
</p>
<a href="https://twitter.com/anirbanray_/status/1694519329159602662">View Tweet</a>
</blockquote>
</div>
<div class="showcase-item twitter-embed" data-priority="immediate">
<blockquote class="twitter-tweet" data-theme="dark">
<p lang="en" dir="ltr">
Loading tweet‚Ä¶
</p>
<a href="https://twitter.com/anirbanray_/status/1699133086640853137">View Tweet</a>
</blockquote>
</div>
<div class="showcase-item twitter-embed" data-priority="immediate">
<blockquote class="twitter-tweet" data-theme="dark">
<p lang="en" dir="ltr">
Loading tweet‚Ä¶
</p>
<a href="https://twitter.com/anirbanray_/status/1699801627522396338">View Tweet</a>
</blockquote>
</div>
<div class="showcase-item twitter-embed" data-priority="immediate">
<blockquote class="twitter-tweet" data-theme="dark">
<p lang="en" dir="ltr">
Loading tweet‚Ä¶
</p>
<a href="https://twitter.com/anirbanray_/status/1692016056695402625">View Tweet</a>
</blockquote>
</div>
<div class="showcase-item twitter-embed" data-priority="immediate">
<blockquote class="twitter-tweet" data-theme="dark">
<p lang="en" dir="ltr">
Loading tweet‚Ä¶
</p>
<a href="https://twitter.com/anirbanray_/status/1761034462781960351">View Tweet</a>
</blockquote>
</div>
<div class="showcase-item twitter-embed" data-priority="immediate">
<blockquote class="twitter-tweet" data-theme="dark">
<p lang="en" dir="ltr">
Loading tweet‚Ä¶
</p>
<a href="https://twitter.com/anirbanray_/status/1789421846225404105">View Tweet</a>
</blockquote>
</div>
<!-- Remaining tweets - load sequentially after first batch -->
<div class="showcase-item twitter-embed" data-priority="lazy">
<blockquote class="twitter-tweet-lazy" data-theme="dark" data-tweet-url="https://twitter.com/anirbanray_/status/1660541006658387969">
<p lang="en" dir="ltr" style="color: #666; text-align: center; padding: 2rem;">
Loading‚Ä¶
</p>
</blockquote>
</div>
<div class="showcase-item twitter-embed" data-priority="lazy">
<blockquote class="twitter-tweet-lazy" data-theme="dark" data-tweet-url="https://twitter.com/anirbanray_/status/1563499736191352835">
<p lang="en" dir="ltr" style="color: #666; text-align: center; padding: 2rem;">
Loading‚Ä¶
</p>
</blockquote>
</div>
<div class="showcase-item linkedin-embed">
<p><iframe src="https://www.linkedin.com/embed/feed/update/urn:li:activity:7196888292766674945" height="600" width="100%" frameborder="0" allowfullscreen="" title="Embedded post"></iframe></p>
</div>
<div class="showcase-item linkedin-embed">
<p><iframe src="https://www.linkedin.com/embed/feed/update/urn:li:activity:7260904021522010112" height="600" width="100%" frameborder="0" allowfullscreen="" title="Embedded post"></iframe></p>
</div>
</div>
<!-- Twitter Widget Script with lazy loading for remaining tweets -->
<script>
(function() {
  // Load Twitter widget script
  var script = document.createElement('script');
  script.src = 'https://platform.twitter.com/widgets.js';
  script.charset = 'utf-8';
  script.async = true;
  
  script.onload = function() {
    // After Twitter widget loads and renders immediate tweets,
    // sequentially load the lazy tweets
    setTimeout(function() {
      var lazyTweets = document.querySelectorAll('.twitter-tweet-lazy');
      var delay = 0;
      
      lazyTweets.forEach(function(placeholder, index) {
        setTimeout(function() {
          var tweetUrl = placeholder.getAttribute('data-tweet-url');
          var theme = placeholder.getAttribute('data-theme');
          
          // Create proper twitter-tweet blockquote
          var blockquote = document.createElement('blockquote');
          blockquote.className = 'twitter-tweet';
          blockquote.setAttribute('data-theme', theme);
          
          var link = document.createElement('a');
          link.href = tweetUrl;
          link.textContent = 'View Tweet';
          blockquote.appendChild(link);
          
          // Replace placeholder with actual blockquote
          placeholder.parentNode.replaceChild(blockquote, placeholder);
          
          // Render the tweet
          if (window.twttr && window.twttr.widgets) {
            twttr.widgets.load(blockquote.parentNode);
          }
        }, delay);
        
        delay += 500; // Load each lazy tweet 500ms apart
      });
    }, 1500); // Wait 1.5s after widget loads before starting lazy tweets
  };
  
  document.head.appendChild(script);
})();
</script>
</section>
<section id="education" class="tab-content" data-tab-id="education">
<h2 class="anchored">Education</h2>
<div class="education-item">
<p><strong>PhD in Computer Science | <em>2022 ‚Äì 2026 (expected)</em></strong> <a href="https://tu-dresden.de" class="flj" target="_blank">Technische Universit√§t Dresden</a> &amp; <a href="https://humantechnopole.it" class="flj" target="_blank">Human Technopole, Italy</a> <br> Advisor: <a href="http://humantechnopole.it/en/people/florian-jug/" class="flj" target="_blank">Dr.&nbsp;Florian Jug</a><br>
Thesis Advisory Committee: <a href="https://sbalzarini-lab.org/?q=people/ivo_sbalzarini" class="flj" target="_blank">Prof.&nbsp;Dr.&nbsp;Ivo F. Sbalzarini</a> and <a href="https://virginieuhlmann.com/" class="flj" target="_blank">Dr.&nbsp;Virginie Uhlmann</a></p>
</div>
<div class="education-item">
<p><strong>Master of Engineering in Computer Science | <em>2016 ‚Äì 2018</em></strong> <a href="https://www.nitech.ac.jp/eng/" class="flj" target="_blank">Nagoya Institute of Technology</a><br>
Advisor: <a href="https://researcher.nitech.ac.jp/html/56_en.html" class="flj" target="_blank">Prof.&nbsp;Jun Sato</a> and <a href="https://researcher.nitech.ac.jp/html/257_en.html" class="flj" target="_blank">Prof.&nbsp;Fumihiko Sakaue</a> | <a href="https://drive.google.com/file/d/1A7Gm2RS3L8SPyb9G9Ey5O350kh7DYZKk/view?usp=sharing" class="flj" target="_blank">Thesis</a></p>
</div>
<div class="education-item">
<p><strong>Research Student | <em>Oct, 2015 ‚Äì Mar, 2016</em></strong> <a href="https://www.nitech.ac.jp/eng/" class="flj" target="_blank">Nagoya Institute of Technology</a><br>
Advisor: <a href="https://researcher.nitech.ac.jp/html/56_en.html" class="flj" target="_blank">Prof.&nbsp;Jun Sato</a> and <a href="https://researcher.nitech.ac.jp/html/257_en.html" class="flj" target="_blank">Prof.&nbsp;Fumihiko Sakaue</a> | Preparatory phase for Master‚Äôs thesis on Computer Vision and Deep Learning.</p>
</div>
<div class="education-item">
<p><strong>Bachelor of Tech. in Computer Science and Engineering | <em>2011 ‚Äì 2015</em></strong> <a href="https://www.veltech.edu.in/" target="_blank">Vel Tech Rangarajan Dr.&nbsp;Sagunthala R&amp;D Institute of Science and Technology</a></p>
</div>
</section>
<section id="teaching-experience" class="tab-content" data-tab-id="teaching">
<h2 class="anchored">Teaching Experience</h2>
<div class="education-item">
<p><strong>Teaching Assistant ‚Äì DL4MIA | <a href="https://humantechnopole.it/en/trainings/deep-learning-for-microscopy-image-analysis-2022/" target="_blank">2022</a>, <a href="https://dl4mia2023.humantechnopole.it/" target="_blank">2023</a>, <a href="https://meetings.embo.org/event/24-deep-learning-mia" class="flj" target="_blank">2024</a><br>
</strong><a href="https://humantechnopole.it/" class="flj" target="_blank">Human Technopole, Milan, Italy</a></p>
<p>Supported the <em>Deep Learning for Microscopy Image Analysis</em> (DL4MIA) course across three consecutive editions. Responsibilities included mentoring participants, <a href="https://x.com/anirbanray_/status/1789421846225404105" target="_blank">invited lecture</a>, coding sessions, and guiding project work on AI-based microscopy restoration and segmentation.</p>
</div>
<div class="education-item">
<p><strong>Teaching Assistant ‚Äì DL@MBL | <a href="https://www.mbl.edu/education/advanced-research-training-courses/courses-calendar?trumbaEmbed=view%3Devent%26eventid%3D164013510" target="_blank">2023</a>, <a href="https://ai-mbl.github.io/2024/about/" target="_blank">2024</a></strong><a href="https://www.mbl.edu/" class="flj" target="_blank">Marine Biological Laboratory, Woods Hole, USA</a></p>
<p>Contributed to hands-on sessions on deep learning for biological imaging. Provided mentoring and technical guidance to participants during lab exercises and research projects. One of the project started in the group that I co-mentored, ended up being published in <a href="https://www.linkedin.com/posts/anirban-ray_our-super-cool-project-bit2bit-1-bit-quanta-activity-7260904021522010112-Nfgi?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAABqfVj4BuGmZW_XROl13l-KT-LedbrI2tzQ" target="_blank">NeurIPS 2024</a> and another work on <a href="https://www.researchsquare.com/article/rs-8059028/v1" target="_blank">improving RESOLFT Microscopy with deep learning</a> is currently under review.</p>
</div>
</section>
<section id="work-experience" class="tab-content" data-tab-id="work">
<h2 class="anchored">Work Experience</h2>
<div class="education-item">
<p><strong>Associate Researcher | <em>Apr 2018 ‚Äì Jan 2022</em></strong> <a href="https://www.hitachi.com/rd/" target="_blank">Hitachi Ltd., Tokyo, Japan</a></p>
<p>Applied Deep Learning and Computer Vision for image analysis in the R&amp;D Group‚Äôs Center for Technology Innovation.</p>
</div>
<div class="education-item">
<p><strong>Engineering Intern (AR Applications) | <em>Sep 2016</em></strong> <a href="https://www.sun-denshi.co.jp/sc/product_service/acereal/" target="_blank">Sun Corporation, Konan, Japan</a></p>
<p>Developed augmented reality applications for AceReal smart glasses using Unity and Vuforia frameworks. Find the official evaluation report in Japanese <a href="files/SunCorp_Internship_Evaluation.pdf" target="_blank">here</a>, and an interactive ChatGPT translated version <a href="https://chatgpt.com/share/693bd2c2-1524-8008-877c-71c1d0f77b69" target="_blank">here</a>.</p>
</div>
<div class="education-item">
<p><strong>Engineering Intern (Cloud Services) | <em>Aug 2014 ‚Äì Jan 2015</em></strong> <a href="https://www.mahindrateqo.com/" target="_blank">Machine Pulse (Mahindra Teqo), Mumbai, India</a></p>
<p>Analyzed large-scale database migration strategies for renewable energy and logistics cloud systems.</p>
</div>
</section>
<section id="special-achievements" class="tab-content" data-tab-id="achievements">
<h2 class="anchored">Special Achievements</h2>
<div class="education-item">
<p><strong>Selected Participant ‚Äì Optical Microscopy &amp; Imaging in the Biomedical Sciences (OMIBS) | <em>2023</em></strong> <a href="https://www.mbl.edu/education/advanced-research-training-courses/course-offerings/optical-microscopy-imaging-biomedical-sciences" target="_blank">Marine Biological Laboratory, USA</a></p>
<p>Selected for this prestigious advanced microscopy course at the Marine Biological Laboratory, covering cutting-edge optical imaging techniques in biomedical sciences. Our <a href="https://x.com/anirbanray_/status/1694519329159602662" class="flj" target="_blank">team won the 3rd Place</a> in microscopy imaging.</p>
</div>
<div class="education-item">
<p><strong>Invited Contributor ‚Äì Alumni Voice Column | <em>2018</em></strong> <a href="https://www.u-tokyo.ac.jp/adm/utindia/en/whyjapan/fromalumni/executive_015.html" target="_blank">The University of Tokyo</a></p>
<p>Invited by the Government of Japan and the University of Tokyo to share academic and professional experiences as part of Japan‚Äôs international education initiative.</p>
</div>
<div class="education-item">
<p><strong>Selected Participant ‚Äì International Computer Vision Summer School (ICVSS) | <em>2017</em></strong> <a href="https://icvss.dmi.unict.it/icvss2017/" target="_blank">ICVSS, Italy</a></p>
<p>Chosen among 150 top global students (mostly PhDs) for advanced training and research presentation in computer vision.</p>
</div>
<div class="education-item">
<p><strong>Aichi Monozukuri Scholarship | <em>2015</em></strong> <a href="https://www.pref.aichi.jp/soshiki/kokusai/aichi-scholarship-program.html" target="_blank">Aichi Prefectural Government, Japan</a></p>
<p>Awarded full funding for Master‚Äôs studies at Nagoya Institute of Technology. Selected among the top 10 students in Asia.</p>
</div>
<div class="education-item">
<p><strong>Selected Participant ‚Äì Undergraduate Summer School on Computer Science | <em>2013</em></strong> <a href="https://www.csa.iisc.ac.in/" target="_blank">Indian Institute of Science, Bengaluru India</a></p>
<p>Chosen among 60 top students from India for advanced topics and research presentation in computer science.</p>
</div>
</section>
<section id="talks" class="tab-content" data-tab-id="talks">
<h2 class="anchored">Talks</h2>
<p class="subtitle" style="margin-bottom: 2rem; color: #a1a0a0ff; font-size: 1.0rem;">
List of my selected talks
</p>
<div style="font-size: 0.95rem;">
<ul>
<li><p><strong><a href="https://arxiv.org/abs/2506.22397" class="flj" target="_blank">HazeMatching</a> at the introduction to ML course</strong> ‚Ä¢ <em>Jul 2025</em><br>
Human Technopole | üìç Milan, Italy</p>
<p><br></p></li>
<li><p><strong><a href="https://arxiv.org/abs/2506.22397" class="flj" target="_blank">HazeMatching</a> at the institute seminar series</strong> ‚Ä¢ <em>Apr 2025</em><br>
Human Technopole | üìç Milan, Italy</p>
<p><br></p></li>
<li><p><strong>Introduction to Diffusion Model for Microscopy</strong> ‚Ä¢ <em>May 2024</em><br>
EMBO-DL4MIA | üìç Milan, Italy</p>
<p><br></p></li>
<li><p><strong>Talk on OpenAI‚Äôs Sora</strong> ‚Ä¢ <em>Feb 2024</em><br>
Human Technopole Research Seminar | üìç Milan, Italy</p>
<p><br></p></li>
<li><p><strong>A talk introducing deep learning and computer vision</strong> ‚Ä¢ <em>Aug 2022</em><br>
Vel Tech University | üìç Chennai, India</p></li>
</ul>
</div>
</section>
<section id="skills" class="tab-content" data-tab-id="skills">
<h2 class="anchored">Skills</h2>
<div class="education-item">
<p><strong>Computational Skills</strong></p>
<p>Python, PyTorch, OpenCV, NumPy, LaTeX, Git, SLURM, Bash, Linux</p>
</div>
<div class="education-item">
<p><strong>Spoken Languages</strong></p>
<p>Bengali (Native), Hindi (Fluent), English (Fluent), Japanese (Conversational), Italian (Elementary)</p>
</div>
</section>
<section id="research" class="tab-content" data-tab-id="research">
<h2 class="anchored">Research</h2>
<h3 id="current-research-phd-2022present" class="anchored">Current Research (PhD, 2022‚ÄìPresent)</h3>
<div class="project-item">
<p><strong><span style="font-size: 1.2em;">RESOLFT time lapse imaging empowered by deep learning</span></strong><br>
<a href="https://www.testalab.org/people.php" class="flj" target="_blank">Guillaume Minet</a>, <a href="https://rayanirban.github.io/" class="flj" target="_blank">Anirban Ray</a>, Francesca Pennacchietti, Giovanna Coceano, <a href="https://humantechnopole.it/en/people/florian-jug/" class="flj" target="_blank">Florian Jug</a>, and <a href="https://www.testalab.org/" class="flj" target="_blank">Ilaria Testa</a><br></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="images/resolft_teaser.png" class="img-fluid quarto-figure quarto-figure-center" style="width:80.0%" alt="RESOLFT time lapse imaging empowered by deep learning"></p>
</figure>
</div>
<p>Deep learning extended RESOLFT nanoscopy by restoring low-SNR and sub-sampled acquisitions, enabling 5√ó longer imaging with 10√ó lower dose of light per frame, or a 4√ó increase in imaging speed for faster live-cell imaging while preserving ~60 nm resolution. This method enables reduced photobleaching and accelerated volumetric recording, revealing previously inaccessible sub-organelle dynamics in living cells.<br> <a href="https://www.researchsquare.com/article/rs-8059028/v1" class="flj" target="_blank">Preprint (under review)</a> | <span class="infographic-wrapper"><a href="files/RESOLFT.png" target="_blank" class="flj">AI Generated infographic</a> <img src="files/RESOLFT.png" class="infographic-pop"></span></p>
</div>
<div class="project-item">
<p><strong><span style="font-size: 1.2em;">ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching <a href="https://biomedicalimaging.org/2026/" class="flj" target="_blank">[IEEE ISBI 2026]</a></span></strong><br>
<a href="https://rayanirban.github.io/" class="flj" target="_blank">Anirban Ray</a>, <a href="https://humantechnopole.it/en/people/vera-galinova/" class="flj" target="_blank">Vera Galinova</a>, and <a href="https://humantechnopole.it/en/people/florian-jug/" class="flj" target="_blank">Florian Jug</a><br> <img src="images/resmatching_teaser.png" class="img-fluid quarto-figure quarto-figure-center" style="width:80.0%" alt="ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching"></p>
<p>A guided conditional flow-matching framework for noise-resilient computational super-resolution in fluorescence microscopy, unifying denoising, super-resolution, uncertainty estimation, and posterior sampling within a single generative model.<br> <!-- [GitHub](#){target="_blank" .flj} | --> <a href="https://arxiv.org/abs/2510.26601" class="flj" target="_blank">Paper (arXiv)</a> | <a href="https://rayanirban.github.io/resmatching/" class="flj" target="_blank">Project Page</a> | <span class="infographic-wrapper"><a href="files/RM.png" target="_blank" class="flj">AI Generated infographic</a> <img src="files/RM.png" class="infographic-pop"></span></p>
</div>
<div class="project-item">
<p><strong><span style="font-size: 1.2em;">HazeMatching: Conditional Flow Matching for Microscopy Dehazing <a href="https://cvpr.thecvf.com/" class="flj" target="_blank">[CVPR 2026 (Findings)]</a></span></strong><br>
<a href="https://rayanirban.github.io/" class="flj" target="_blank">Anirban Ray</a>, <a href="https://ashesh-0.github.io/" class="flj" target="_blank">Ashesh</a>, and <a href="https://humantechnopole.it/en/people/florian-jug/" class="flj" target="_blank">Florian Jug</a><br><br>
<img src="images/hazematching_teaser.png" class="img-fluid quarto-figure quarto-figure-center" style="width:80.0%" alt="HazeMatching: Conditional Flow Matching for microscopy dehazing"></p>
<p>A generative framework that restores optical microscopy images degraded by scattering and haze using Conditional Flow Matching (CFM). HazeMatching models the mapping between widefield and confocal modalities, enabling clearer visualization of biological structures.<br> <!-- [GitHub](#){target="_blank" .flj} | --> <a href="https://arxiv.org/abs/2506.22397" class="flj" target="_blank">Paper (arXiv)</a> | <!-- [Project Page](#){target="_blank"} | --> <span class="infographic-wrapper"><a href="files/HM.png" target="_blank" class="flj">AI Generated infographic</a> <img src="files/HM.png" class="infographic-pop"></span></p>
</div>
<h3 id="past-research-hitachi-ltd.-20182021" class="anchored">Past Research (Hitachi Ltd., 2018‚Äì2021)</h3>
<div class="project-item">
<p><strong>Deep Learning for Microscopy Image Analysis</strong></p>
<p>From 2018 to 2021, my research at <a href="https://www.hitachi.com/rd/" class="flj" target="_blank">Hitachi Ltd., Tokyo</a> focused on developing deep learning‚Äìbased systems for high-precision image understanding in biomedical microscopy. I worked on combining computer vision and AI-driven automation for identifying and quantifying objects of interest in complex visual data.</p>
<p><strong>Publications:</strong></p>
<ul>
<li><a href="https://ieeexplore.ieee.org/abstract/document/9400322" class="flj" target="_blank"><em>Quantitative Analysis System for Bacterial Cells in SEM Images Using Deep Learning</em></a> (<em>CISS 2021</em>) ‚Äî introduced a neural architecture for accurate segmentation and counting of bacterial cells from scanning electron microscopy (SEM) data. | <span class="infographic-wrapper"><a href="files/HitPaper2.png" target="_blank" class="flj">AI Generated infographic</a> <img src="files/HitPaper2.png" class="infographic-pop"></span></li>
<li><a href="https://ieeexplore.ieee.org/abstract/document/9751170" class="flj" target="_blank"><em>Deep Learning Based Bacteria Classification from SEM Images Using a Combination of Membrane and Internal Features</em></a> (<em>CISS 2022</em>) ‚Äî improved bacterial classification by jointly modeling morphological and internal structural cues. | <span class="infographic-wrapper"><a href="files/HitPaper1.png" target="_blank" class="flj">AI Generated infographic</a> <img src="files/HitPaper1.png" class="infographic-pop"></span></li>
</ul>
<p><strong>Patents:</strong></p>
<ul>
<li><a href="https://patents.google.com/patent/US12327363B2" class="flj" target="_blank">US Patent 12327363</a> ‚Äî methods and apparatuses for generating neural models that identify and segment objects of interest from images. | <span class="infographic-wrapper"><a href="files/USP2.png" target="_blank" class="flj">AI Generated infographic</a> <img src="files/USP2.png" class="infographic-pop"></span></li>
<li><a href="https://patents.google.com/patent/US12211213B2" class="flj" target="_blank">US Patent 12211213</a> ‚Äî adaptive feature extraction and object detection for microscopy imaging. | <span class="infographic-wrapper"><a href="files/USP1.png" target="_blank" class="flj">AI Generated infographic</a> <img src="files/USP1.png" class="infographic-pop"></span></li>
<li><a href="https://patents.google.com/patent/EP3961562A1" class="flj" target="_blank">EP Patent 3961562A1</a> ‚Äî AI image-processing systems for industrial and microscopy applications. | <span class="infographic-wrapper"><a href="files/EP.png" target="_blank" class="flj">AI Generated infographic</a> <img src="files/EP.png" class="infographic-pop"></span></li>
</ul>
<p>This phase of my work established a foundation in AI-driven visual understanding, bridging industrial automation with quantitative biological imaging, and set the stage for my later research in generative and flow-based models for microscopy restoration.</p>
<div class="quarto-figure quarto-figure-center" style="border-radius: 1rem; box-shadow: 0 0 10px rgba(0,0,0,0.1);">
<figure>
<p><img src="images/past_research_teaser.png" class="img-fluid" style="width:100.0%"></p>
<figcaption><strong>Figure:</strong> Conceptual schematic of deep learning pipelines developed at Hitachi for automated bacterial analysis and industrial image understanding.</figcaption>
</figure>
</div>
</div>
<h3 id="past-research-masters-thesis-20162018" class="anchored">Past Research (Masters Thesis, 2016‚Äì2018)</h3>
<div class="project-item">
<p><strong><span style="font-size: 1.2em;">Modeling the Feature Evolution in CNNs using LSTM</span></strong><br>
<img src="images/masters.png" class="img-fluid quarto-figure quarto-figure-center" style="width:80.0%" alt="Modeling the Feature Evolution in CNNs using LSTM"></p>
<p>During my master‚Äôs studies at <a href="https://www.nitech.ac.jp/eng/" class="flj" target="_blank">Nagoya Institute of Technology</a>, Japan (2018), I explored the temporal dynamics of feature representations in Convolutional Neural Networks (CNNs) using Long Short-Term Memory (LSTM) networks. My research focused on understanding how features evolve across layers in CNNs and leveraging LSTMs to model these transitions for improved image classification performance. Read more about it in my <a href="https://drive.google.com/file/d/1A7Gm2RS3L8SPyb9G9Ey5O350kh7DYZKk/view?usp=sharing" class="flj" target="_blank">thesis.</a> | <span class="infographic-wrapper"><a href="files/Thesis.png" target="_blank" class="flj">AI Generated infographic</a> <img src="files/Thesis.png" class="infographic-pop"></span></p>
</div>
<p style="font-size: 0.8em; color: #ff4d4d; text-align: center; margin-top: 3rem; font-style: italic;">
(Note that AI Generated infographics are representational only)
</p>
</section>
</div>
<div class="right-side-column">
<section id="news" class="news-block">
<h3 class="anchored">News</h3>
<div class="news-items-container">
<!-- ::: {.news-item}
<span class="news-date">Mar 2026</span>
<div class="news-content">Presenting our [poster](files/EMBL_poster.pdf){target="_blank" .flj} on [HazeMatching](https://arxiv.org/abs/2506.22397){target="_blank" .flj} and [ResMatching](https://rayanirban.github.io/resmatching/){target="_blank" .flj} at the [AI and Biology Symposium 2026](https://www.embl.org/about/info/course-and-conference-office/events/ees26-02/){target="_blank" .flj} at [EMBL](https://www.embl.org/sites/heidelberg/){target="_blank" .flj} in Heidelberg, Germany. If you're around please drop by!</div>
::: -->
<div class="news-item">
<span class="news-date">Feb 2026</span>
<div class="news-content">
<a href="https://arxiv.org/abs/2506.22397" class="flj" target="_blank">HazeMatching</a> has been accepted to <a href="https://cvpr.thecvf.com/" class="flj" target="_blank">CVPR 2026 (Findings)</a> üéâüéâ. More details soon!
</div>
</div>
<!-- ::: {.news-item}
<span class="news-date">Feb 2026</span>
<div class="news-content">[HazeMatching](https://arxiv.org/abs/2506.22397){target="_blank" .flj} has been accepted to [CVPR 2026 (Findings)](https://cvpr.thecvf.com/){target="_blank" .flj} üéâüéâ. Read the story [here.](){target="_blank" .flj}</div>
::: -->
<div class="news-item">
<span class="news-date">Jan 2026</span>
<div class="news-content">
Wrote a short <a href="https://x.com/anirbanray_/status/2012732617569800368" class="flj" target="_blank">thread</a> on why I believe <a href="https://arxiv.org/abs/2209.03003" class="flj" target="_blank">Rectified Flow</a> is not the best choice for scientific imaging inverse problems.
</div>
</div>
<div class="news-item">
<span class="news-date">Jan 2026</span>
<div class="news-content">
<a href="https://rayanirban.github.io/resmatching/" class="flj" target="_blank">ResMatching</a> has been accepted to <a href="https://biomedicalimaging.org/2026/" class="flj" target="_blank">IEEE ISBI 2026</a> üéâüéâ. Read the story <a href="https://www.linkedin.com/posts/anirban-ray_isbi2026-generativeai-flowmatching-activity-7417062191268462592-mC8_?utm_source=social_share_send&amp;utm_medium=member_desktop_web&amp;rcm=ACoAABqfVj4BuGmZW_XROl13l-KT-LedbrI2tzQ" class="flj" target="_blank">here.</a>
</div>
</div>
<div class="news-item">
<span class="news-date">Jan 2026</span>
<div class="news-content">
Selected for poster presentation on <a href="https://arxiv.org/abs/2506.22397" class="flj" target="_blank">HazeMatching</a> and <a href="https://rayanirban.github.io/resmatching/" class="flj" target="_blank">ResMatching</a> at the <a href="https://www.embl.org/about/info/course-and-conference-office/events/ees26-02/" class="flj" target="_blank">AI and Biology Symposium 2026</a> to be held at <a href="https://www.embl.org/sites/heidelberg/" class="flj" target="_blank">EMBL</a> in Heidelberg, Germany üéâ.
</div>
</div>
<div class="news-item">
<span class="news-date">Dec 2025</span>
<div class="news-content">
Preprint of <a href="https://www.researchsquare.com/article/rs-8059028/v1" class="flj" target="_blank">RESOLFT with Deep Learning</a> is now available üéâ
</div>
</div>
<div class="news-item">
<span class="news-date">Oct 2025</span>
<div class="news-content">
<a href="https://rayanirban.github.io/resmatching/" class="flj" target="_blank">ResMatching</a> is now on <em>arXiv</em> üéâ
</div>
</div>
<div class="news-item">
<span class="news-date">Sep 2025</span>
<div class="news-content">
This <a href="https://github.com/ai4life-opencalls/oc2_project_23?tab=readme-ov-file#213-hazematching" class="flj" target="_blank">AI4Life project</a> demonstarted that <a href="https://arxiv.org/abs/2506.22397" class="flj" target="_blank">HazeMatching</a> also seem to work well for image super-resolution tasks on Expansion Microscopy Data üò±
</div>
</div>
<div class="news-item">
<span class="news-date">Jul 2025</span>
<div class="news-content">
Presented <a href="https://arxiv.org/abs/2506.22397" class="flj" target="_blank">HazeMatching</a> at the Human Technopole institute Introduction to ML course
</div>
</div>
<div class="news-item">
<span class="news-date">Jun 2025</span>
<div class="news-content">
<a href="https://arxiv.org/abs/2506.22397" class="flj" target="_blank">HazeMatching</a> is now on <em>arXiv</em> üéâ
</div>
</div>
<div class="news-item">
<span class="news-date">Apr 2025</span>
<div class="news-content">
Presented <a href="https://arxiv.org/abs/2506.22397" class="flj" target="_blank">HazeMatching</a> at the Human Technopole institute seminar series
</div>
</div>
<div class="news-item">
<span class="news-date">Oct 2024</span>
<div class="news-content">
Attended <a href="https://eccv.ecva.net/Conferences/2024" class="flj" target="_blank">ECCV 2024</a>
</div>
</div>
<div class="news-item">
<span class="news-date">Oct 2024</span>
<div class="news-content">
Presented my Poster at <a href="https://events.humantechnopole.it/event/1/contributions/81/" class="flj" target="_blank">I2K 2024</a>
</div>
</div>
<div class="news-item">
<span class="news-date">Aug 2024</span>
<div class="news-content">
TAing at <a href="https://ai-mbl.github.io/2024/about/" class="flj" target="_blank">DL@MBL 2024</a>
</div>
</div>
<div class="news-item">
<span class="news-date">May 2024</span>
<div class="news-content">
Served as a reviewer for the <a href="https://ai4life.eurobioimaging.eu/first-ai4life-open-call-announcement-of-selected-projects/" target="_blank">AI4Life Open Call</a> and received my official reviewer <a href="https://api.badgr.io/public/assertions/OsueugVFSI22qBgKaqTgdg" target="_blank">badge üòä
</a></div><a href="https://api.badgr.io/public/assertions/OsueugVFSI22qBgKaqTgdg" target="_blank">
</a></div><a href="https://api.badgr.io/public/assertions/OsueugVFSI22qBgKaqTgdg" target="_blank">
</a><div class="news-item"><a href="https://api.badgr.io/public/assertions/OsueugVFSI22qBgKaqTgdg" target="_blank">
<span class="news-date">May 2024</span>
</a><div class="news-content"><a href="https://api.badgr.io/public/assertions/OsueugVFSI22qBgKaqTgdg" target="_blank">
TAing at </a><a href="https://meetings.embo.org/event/24-deep-learning-mia" class="flj" target="_blank">EMBO-DL4MIA 2024</a> and <a href="https://x.com/anirbanray_/status/1789421846225404105" class="flj" target="_blank">Invited talk</a> at EMBO-DL4MIA 2024
</div>
</div>
<div class="news-item">
<span class="news-date">Feb 2024</span>
<div class="news-content">
<a href="https://x.com/anirbanray_/status/1761034462781960351" class="flj" target="_blank">Talk</a> on OpenAI‚Äôs Sora at Human Technopole
</div>
</div>
<div class="news-item">
<span class="news-date">Oct 2023</span>
<div class="news-content">
TAing at <a href="https://dl4mia2023.humantechnopole.it/" class="flj" target="_blank">DL4MIA 2023</a>
</div>
</div>
<div class="news-item">
<span class="news-date">Aug 2023</span>
<div class="news-content">
TAing at <a href="https://www.mbl.edu/education/advanced-research-training-courses/courses-calendar?trumbaEmbed=view%3Devent%26eventid%3D164013510" class="flj" target="_blank">DL@MBL 2023</a>
</div>
</div>
<div class="news-item">
<span class="news-date">Aug 2023</span>
<div class="news-content">
Our <a href="https://x.com/anirbanray_/status/1694519329159602662" class="flj" target="_blank">team won the 3rd Place</a> in microscopy imaging at Optical Microscopy &amp; Imaging in the Biomedical Sciences course
</div>
</div>
<div class="news-item">
<span class="news-date">Aug 2023</span>
<div class="news-content">
Attending <a href="https://www.mbl.edu/education/advanced-research-training-courses/course-offerings/optical-microscopy-imaging-biomedical-sciences" class="flj" target="_blank">Optical Microscopy &amp; Imaging in the Biomedical Sciences</a> at the Marine Biological Laboratory, USA
</div>
</div>
<div class="news-item">
<span class="news-date">May 2023</span>
<div class="news-content">
Attending Light Microscopy Course at <a href="https://scopem.ethz.ch/education/MTP/IC/LM1.html" class="flj" target="_blank">ETH, Zurich</a>
</div>
</div>
<div class="news-item">
<span class="news-date">Dec 2022</span>
<div class="news-content">
<a href="https://x.com/anirbanray_/status/1600465694839123968" class="flj" target="_blank">Attended</a> <a href="https://rt-maiages.math.cnrs.fr/mia25/mia25/" class="flj" target="_blank">Mathematics and Image Analysis Workshop</a> in Paris
</div>
</div>
<div class="news-item">
<span class="news-date">Oct 2022</span>
<div class="news-content">
Officially enrolled as a PhD candidate at <a href="https://tu-dresden.de" class="flj" target="_blank">Technische Universit√§t Dresden</a>
</div>
</div>
<div class="news-item">
<span class="news-date">Sep 2022</span>
<div class="news-content">
<a href="https://rayanirban.notion.site/The-Computer-Science-Craze-in-Undergraduate-Education-in-India-6f329314710d40dc8ab099d296a3c4ab" class="flj" target="_blank">My thoughts</a> on the current craze of computer science among Indian Students.
</div>
</div>
<div class="news-item">
<span class="news-date">Aug 2022</span>
<div class="news-content">
I <a href="https://x.com/anirbanray_/status/1563499736191352835" class="flj" target="_blank">gave a talk</a> introducing deep learning and computer vision to the students at my undergrad institution.
</div>
</div>
<div class="news-item">
<span class="news-date">Jul 2022</span>
<div class="news-content">
TAing at <a href="https://humantechnopole.it/en/trainings/deep-learning-for-microscopy-image-analysis-2022/" class="flj" target="_blank">DL4MIA 2022</a>
</div>
</div>
<div class="news-item">
<span class="news-date">Feb 2022</span>
<div class="news-content">
<a href="https://youtu.be/5skjz4Fe044?t=15" class="flj" target="_blank">Started my PhD</a> with <a href="http://humantechnopole.it/en/people/florian-jug/" class="flj" target="_blank">Florian Jug</a> at <a href="https://humantechnopole.it" class="flj" target="_blank">Human Technopole, Italy</a>
</div>
</div>
<div class="news-item">
<span class="news-date">Jan 2022</span>
<div class="news-content">
Left my job at <a href="https://www.hitachi.com/rd/" class="flj" target="_blank">Hitachi Research</a>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
<div style="text-align: center; color: gray; font-size: 0.75rem; margin-top: 0.5rem; padding-bottom: 1rem;">
<p>If you use this template, please acknowledge this original design üòä</p>
</div>
<script>
document.addEventListener('DOMContentLoaded', function() {
  const navTabs = document.querySelectorAll('.nav-tab');
  const tabContents = document.querySelectorAll('.tab-content');
  
  navTabs.forEach(tab => {
    tab.addEventListener('click', function(e) {
      e.preventDefault();
      
      // Remove active class from all tabs and contents
      navTabs.forEach(t => t.classList.remove('active'));
      tabContents.forEach(content => content.classList.remove('active'));
      
      // Add active class to clicked tab
      this.classList.add('active');
      
      // Show corresponding content
      const tabId = this.getAttribute('data-tab');
      const contentToShow = document.querySelector(`[data-tab-id="${tabId}"]`);
      if (contentToShow) {
        contentToShow.classList.add('active');
        
        // Toggle showcase-active class on body for hiding sidebars
        // This provides better browser support than CSS :has() selector
        if (tabId === 'showcase') {
          document.body.classList.add('showcase-active');
        } else {
          document.body.classList.remove('showcase-active');
        }
        
        // Scroll to the content on mobile
        setTimeout(() => {
          const rightPanel = document.querySelector('.right-panel');
          if (rightPanel && window.innerWidth <= 800) {
            rightPanel.scrollIntoView({ behavior: 'smooth', block: 'start' });
          }
        }, 100);
      }
    });
  });
});
</script>


<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
    tabsets.forEach(function(tabset) {
      const tabby = new Tabby('#' + tabset.id);
    });
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/rayanirban\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>




</body></html>